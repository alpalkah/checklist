{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import checklist\n",
    "import spacy\n",
    "import itertools\n",
    "\n",
    "import checklist.editor\n",
    "import checklist.text_generation\n",
    "from checklist.test_types import MFT, INV, DIR\n",
    "from checklist.expect import Expect\n",
    "from checklist.test_suite import TestSuite\n",
    "import numpy as np\n",
    "import spacy\n",
    "from checklist.perturb import Perturb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/marcotcr/work/ml-tests/')\n",
    "from mltests import bert_squad_model\n",
    "from checklist.pred_wrapper import PredictorWrapper\n",
    "model = bert_squad_model.BertSquad()\n",
    "\n",
    "invert = lambda a: model.predict_pairs([(x[1], x[0]) for x in a])\n",
    "new_pp = PredictorWrapper.wrap_predict(invert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'checkers'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AutoModelForQuestionAnswering \n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mchecklist\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpred_wrapper\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PredictorWrapper\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcheckers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m qa_model\n\u001b[32m      5\u001b[39m model_name = \u001b[33m\"\u001b[39m\u001b[33m./output/trained_model/\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      7\u001b[39m qa = qa_model(model_name)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'checkers'"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForQuestionAnswering \n",
    "from checklist.pred_wrapper import PredictorWrapper\n",
    "\n",
    "from checkers import qa_model\n",
    "model_name = \"./output/trained_model/\"\n",
    "    \n",
    "qa = qa_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function that wraps AutoModelForQuestionAnswering to answer a question given a context\n",
    "\n",
    "\n",
    "# model.predict_pairs([('Who is smarter?', 'John is smart')])\n",
    "\n",
    "context = \"John is smart.\"\n",
    "question = \"Who is smarter?\"\n",
    "answer = qa.answer_question(context, question)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invert([('John is smart', 'Who is smart')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "editor = checklist.editor.Editor()\n",
    "editor.tg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_squad_with_context(x, pred, conf, label=None, *args, **kwargs):\n",
    "    c, q = x\n",
    "    ret = 'C: %s\\nQ: %s\\n' % (c, q)\n",
    "    if label is not None:\n",
    "        ret += 'A: %s\\n' % label\n",
    "    ret += 'P: %s\\n' % pred\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_squad(x, pred, conf, label=None, *args, **kwargs):\n",
    "    c, q = x\n",
    "    ret = 'Q: %s\\n' % (q)\n",
    "    if label is not None:\n",
    "        ret += 'A: %s\\n' % label\n",
    "    ret += 'P: %s\\n' % pred\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def load_squad(fold='validation'):\n",
    "    answers = []\n",
    "    data = []\n",
    "    ids = []\n",
    "    files = {\n",
    "        'validation': '/home/marcotcr/datasets/squad/dev-v1.1.json',\n",
    "        'train': '/home/marcotcr//datasets/squad/train-v1.1.json',\n",
    "        }\n",
    "    f = json.load(open(files[fold]))\n",
    "    for t in f['data']:\n",
    "        for p in t['paragraphs']:\n",
    "            context = p['context']\n",
    "            for qa in p['qas']:\n",
    "                data.append({'passage': context, 'question': qa['question'], 'id': qa['id']})\n",
    "                answers.append(set([(x['text'], x['answer_start']) for x in qa['answers']]))\n",
    "    return data, answers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "data, answers =  load_squad()\n",
    "spacy_map =  pickle.load(open('/home/marcotcr/tmp/processed_squad.pkl', 'rb'))\n",
    "pairs = [(x['passage'], x['question']) for x in data]\n",
    "processed_pairs = [(spacy_map[x[0]], spacy_map[x[1]]) for x in pairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suite = TestSuite()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(', '.join(editor.suggest('{first_name} is {mask} than {first_name2}.')[:60]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj = ['old', 'smart', 'tall', 'young', 'strong', 'short', 'tough', 'cool', 'fast', 'nice', 'small', 'dark', 'wise', 'rich', 'great', 'weak', 'high', 'slow', 'strange', 'clean']\n",
    "adj = [(x.rstrip('e'), x) for x in adj]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'adj' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43madj\u001b[49m[\u001b[32m2\u001b[39m]\n",
      "\u001b[31mNameError\u001b[39m: name 'adj' is not defined"
     ]
    }
   ],
   "source": [
    "adj[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = editor.template(\n",
    "    [(\n",
    "    '{first_name} is {adj[0]}er than {first_name1}.',\n",
    "    'Who is less {adj[1]}?'\n",
    "    ),(\n",
    "    '{first_name} is {adj[0]}er than {first_name1}.',\n",
    "    'Who is {adj[0]}er?'\n",
    "    )\n",
    "    ],\n",
    "    labels = ['{first_name1}','{first_name}'],\n",
    "    adj=adj,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=500,\n",
    "    save=True\n",
    "    )\n",
    "name = 'A is COMP than B. Who is more / less COMP?'\n",
    "description = ''\n",
    "test = MFT(**t, name=name, description=description, capability='Vocabulary')\n",
    "test.run(new_pp)\n",
    "test.summary(n=3, format_example_fn=format_squad_with_context)\n",
    "suite.add(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossproduct(t):\n",
    "    # takes the output of editor.template and does the cross product of contexts and qas\n",
    "    ret = []\n",
    "    ret_labels = []\n",
    "    for x in t.data:\n",
    "        cs = x['contexts']\n",
    "        qas = x['qas']\n",
    "        d = list(itertools.product(cs, qas))\n",
    "        ret.append([(x[0], x[1][0]) for x in d])\n",
    "        ret_labels.append([x[1][1] for x in d])\n",
    "    t.data = ret\n",
    "    t.labels = ret_labels\n",
    "    return t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = editor.suggest('John is very {mask} about the project.')[:20]\n",
    "print(', '.join(editor.suggest('John is {mask} {state} about the project.', state=state)[:30]))\n",
    "very = ['very', 'extremely', 'really', 'quite', 'incredibly', 'particularly', 'highly', 'super']\n",
    "somewhat = ['a little', 'somewhat', 'slightly', 'mildly']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{first_name} is {very} {s} about the project. {first_name1} is {s} about the project.',\n",
    "            '{first_name1} is {s} about the project. {first_name} is {very} {s} about the project.',\n",
    "            '{first_name} is {s} about the project. {first_name1} is {somewhat} {s} about the project.',\n",
    "            '{first_name1} is {somewhat} {s} about the project. {first_name} is {s} about the project.',\n",
    "            '{first_name} is {very} {s} about the project. {first_name1} is {somewhat} {s} about the project.',\n",
    "            '{first_name1} is {somewhat} {s} about the project. {first_name} is {very} {s} about the project.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'Who is most {s} about the project?',\n",
    "                '{first_name}'\n",
    "            ), \n",
    "            (\n",
    "                'Who is least {s} about the project?',\n",
    "                '{first_name1}'\n",
    "            ), \n",
    "            \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    s = state,\n",
    "    very=very,\n",
    "    somewhat=somewhat,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=500,\n",
    "    save=True\n",
    "    ))\n",
    "name = 'Intensifiers (very, super, extremely) and reducers (somewhat, kinda, etc)?'\n",
    "desc = ''\n",
    "test = MFT(**t, name=name, description=desc, capability='Vocabulary')\n",
    "test.run(new_pp)\n",
    "test.summary(n=3, format_example_fn=format_squad_with_context)\n",
    "suite.add(test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taxonomy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Size, chape, color, age, material"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import munch\n",
    "order = ['size', 'shape', 'age', 'color']\n",
    "props = []\n",
    "properties = {\n",
    "    'color' : ['red', 'blue','yellow', 'green', 'pink', 'white', 'black', 'orange', 'grey', 'purple', 'brown'],\n",
    "    'size' : ['big', 'small', 'tiny', 'enormous'],\n",
    "    'age' : ['old', 'new'],\n",
    "    'shape' : ['round', 'oval', 'square', 'triangular'],\n",
    "    'material' : ['iron', 'wooden', 'ceramic', 'glass', 'stone']\n",
    "}\n",
    "for i in range(len(order)):\n",
    "    for j in range(i + 1, len(order)):\n",
    "        p1, p2 = order[i], order[j]\n",
    "        for v1, v2 in itertools.product(properties[p1], properties[p2]):\n",
    "            props.append(munch.Munch({\n",
    "                'p1': p1,\n",
    "                'p2': p2,\n",
    "                'v1': v1,\n",
    "                'v2': v2,\n",
    "            }))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(', '.join(editor.suggest('There is {a:p.v1} {p.v2} {mask} in the room.', p=props, verbose=False)[:30]))\n",
    "objects = ['box', 'clock', 'table', 'object', 'toy', 'painting', 'sculpture', 'thing', 'figure']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            'There is {a:p.v1} {p.v2} {obj} in the room.',\n",
    "            'There is {a:obj} in the room. The {obj} is {p.v1} and {p.v2}.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'What {p.p1} is the {obj}?',\n",
    "                '{p.v1}'\n",
    "            ), \n",
    "            (\n",
    "                'What {p.p2} is the {obj}?',\n",
    "                '{p.v2}'\n",
    "            ), \n",
    "            \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    obj=objects,\n",
    "    p=props,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=500,\n",
    "    save=True\n",
    "    ))\n",
    "name = 'size, shape, age, color'\n",
    "desc = ''\n",
    "test = MFT(**t, name=name, description=desc, capability='Taxonomy')\n",
    "test.run(new_pp)\n",
    "test.summary(n=3, format_example_fn=format_squad_with_context)\n",
    "suite.add(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Professions vs nationalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "professions = editor.suggest('{first_name} works as {a:mask}.')[:30]\n",
    "professions += editor.suggest('{first_name} {last_name} works as {a:mask}.')[:30]\n",
    "professions = list(set(professions))\n",
    "if 'translator' in professions:\n",
    "    professions.remove('translator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(string):\n",
    "    return string.lstrip('[a,the,an,in,at] ').rstrip('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expect_squad(x, pred, conf, label=None, meta=None):\n",
    "    return clean(pred) == clean(label)\n",
    "expect_squad = Expect.single(expect_squad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{first_name} is {a:nat} {prof}.',\n",
    "            '{first_name} is {a:prof}. {first_name} is {nat}.',\n",
    "            '{first_name} is {nat}. {first_name} is {a:prof}.',\n",
    "            '{first_name} is {nat} and {a:prof}.',\n",
    "            '{first_name} is {a:prof} and {nat}.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'What is {first_name}\\'s job?',\n",
    "                '{prof}'\n",
    "            ), \n",
    "            (\n",
    "                'What is {first_name}\\'s nationality?',\n",
    "                '{nat}'\n",
    "            ), \n",
    "            \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    nat = editor.lexicons['nationality'][:10],\n",
    "    prof=professions,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=500,\n",
    "    save=True,\n",
    "    ))\n",
    "name = 'Profession vs nationality'\n",
    "test = MFT(**t, name=name, expect=expect_squad, description='',  capability='Taxonomy')\n",
    "test.run(new_pp)\n",
    "test.summary(n=3, format_example_fn=format_squad_with_context)\n",
    "suite.add(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Animal vs vehicle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animals = ['dog', 'cat', 'bull', 'cow', 'fish', 'serpent', 'snake', 'lizard', 'hamster', 'rabbit', 'guinea pig', 'iguana', 'duck']\n",
    "vehicles = ['car', 'truck', 'train', 'motorcycle', 'bike', 'firetruck', 'tractor', 'van', 'SUV', 'minivan']\n",
    "t = crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{first_name} has {a:animal} and {a:vehicle}.',\n",
    "            '{first_name} has {a:vehicle} and {a:animal}.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'What animal does {first_name} have?',\n",
    "                '{animal}'\n",
    "            ), \n",
    "            (\n",
    "                'What vehicle does {first_name} have?',\n",
    "                '{vehicle}'\n",
    "            ), \n",
    "            \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    animal=animals,\n",
    "    vehicle=vehicles,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=500,\n",
    "    save=True\n",
    "    ))\n",
    "name = 'Animal vs Vehicle'\n",
    "test = MFT(**t, name=name, description='', capability='Taxonomy', expect=expect_squad)\n",
    "test.run(new_pp)\n",
    "test.summary(n=3, format_example_fn=format_squad_with_context)\n",
    "suite.add(test, overwrite=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animals = ['dog', 'cat', 'bull', 'cow', 'fish', 'serpent', 'snake', 'lizard', 'hamster', 'rabbit', 'guinea pig', 'iguana', 'duck']\n",
    "vehicles = ['car', 'truck', 'train', 'motorcycle', 'bike', 'firetruck', 'tractor', 'van', 'SUV', 'minivan']\n",
    "t = crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{first_name} bought {a:animal}. {first_name2} bought {a:vehicle}.',\n",
    "            '{first_name2} bought {a:vehicle}. {first_name} bought {a:animal}.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'Who bought an animal?',\n",
    "                '{first_name}'\n",
    "            ), \n",
    "            (\n",
    "                'Who bought a vehicle?',\n",
    "                '{first_name2}'\n",
    "            ), \n",
    "            \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    animal=animals,\n",
    "    vehicle=vehicles,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=500,\n",
    "    save=True\n",
    "    ))\n",
    "name = 'Animal vs Vehicle v2'\n",
    "test = MFT(**t, name=name, description='', capability='Taxonomy', expect=expect_squad)\n",
    "test.run(new_pp)\n",
    "test.summary(n=3, format_example_fn=format_squad_with_context)\n",
    "suite.add(test, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synonyms = [ ('spiritual', 'religious'), ('angry', 'furious'), ('organized', 'organised'),\n",
    "            ('vocal', 'outspoken'), ('grateful', 'thankful'), ('intelligent', 'smart'),\n",
    "            ('humble', 'modest'), ('courageous', 'brave'), ('happy', 'joyful'), ('scared', 'frightened'),\n",
    "           ]\n",
    "\n",
    "t = crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{first_name} is very {s1[0]}. {first_name2} is very {s2[0]}.',\n",
    "            '{first_name2} is very {s2[0]}. {first_name} is very {s1[0]}.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'Who is {s1[1]}?',\n",
    "                '{first_name}'\n",
    "            ), \n",
    "            (\n",
    "                'Who is {s2[1]}?',\n",
    "                '{first_name2}'\n",
    "            ), \n",
    "            \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    s=synonyms,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=250,\n",
    "    save=True\n",
    "   ))\n",
    "t += crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{first_name} is very {s1[1]}. {first_name2} is very {s2[1]}.',\n",
    "            '{first_name2} is very {s2[1]}. {first_name} is very {s1[1]}.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'Who is {s1[0]}?',\n",
    "                '{first_name}'\n",
    "            ), \n",
    "            (\n",
    "                'Who is {s2[0]}?',\n",
    "                '{first_name2}'\n",
    "            ), \n",
    "            \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    s=synonyms,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=250,\n",
    "    save=True\n",
    "    )) \n",
    "name = 'Synonyms'\n",
    "test = MFT(**t, name=name, description='', capability='Taxonomy', expect=expect_squad)\n",
    "test.run(new_pp)\n",
    "test.summary(n=3, format_example_fn=format_squad_with_context)\n",
    "suite.add(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_pairs = [('better', 'worse'), ('older', 'younger'), ('smarter', 'dumber'), ('taller', 'shorter'), ('bigger', 'smaller'), ('stronger', 'weaker'), ('faster', 'slower'), ('darker', 'lighter'), ('richer', 'poorer'), ('happier', 'sadder'), ('louder', 'quieter'), ('warmer', 'colder')]\n",
    "comp_pairs = list(set(comp_pairs))#list(set(comp_pairs + [(x[1], x[0]) for x in comp_pairs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{first_name} is {comp[0]} than {first_name1}.',\n",
    "            '{first_name1} is {comp[1]} than {first_name}.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'Who is {comp[1]}?',\n",
    "                '{first_name1}',\n",
    "            ),\n",
    "            (\n",
    "                'Who is {comp[0]}?',\n",
    "                '{first_name}',\n",
    "            )\n",
    "            \n",
    "        ]\n",
    "        ,\n",
    "    },\n",
    "    comp=comp_pairs,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=500,\n",
    "    save=True\n",
    "    ))\n",
    "name = 'A is COMP than B. Who is antonym(COMP)? B'\n",
    "test = MFT(**t, name=name, description='', capability='Taxonomy')\n",
    "test.run(new_pp)\n",
    "test.summary(n=3, format_example_fn=format_squad_with_context)\n",
    "suite.add(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "antonym_adjs = [('progressive', 'conservative'),('religious', 'secular'),('positive', 'negative'),('defensive', 'offensive'),('rude',  'polite'),('optimistic', 'pessimistic'),('stupid', 'smart'),('negative', 'positive'),('unhappy', 'happy'),('active', 'passive'),('impatient', 'patient'),('powerless', 'powerful'),('visible', 'invisible'),('fat', 'thin'),('bad', 'good'),('cautious', 'brave'), ('hopeful', 'hopeless'),('insecure', 'secure'),('humble', 'proud'),('passive', 'active'),('dependent', 'independent'),('pessimistic', 'optimistic'),('irresponsible', 'responsible'),('courageous', 'fearful')]\n",
    "t = crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{first_name} is more {a[0]} than {first_name1}.',\n",
    "            '{first_name1} is more {a[1]} than {first_name}.',\n",
    "            '{first_name} is less {a[1]} than {first_name1}.',\n",
    "            '{first_name1} is less {a[0]} than {first_name}.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'Who is more {a[0]}?',\n",
    "                '{first_name}',\n",
    "            ),\n",
    "            (\n",
    "                'Who is less {a[0]}?',\n",
    "                '{first_name1}',\n",
    "            ),\n",
    "            (\n",
    "                'Who is more {a[1]}?',\n",
    "                '{first_name1}',\n",
    "            ),\n",
    "            (\n",
    "                'Who is less {a[1]}?',\n",
    "                '{first_name}',\n",
    "            ),\n",
    "        ]\n",
    "        ,\n",
    "    },\n",
    "    a = antonym_adjs,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=500,\n",
    "    save=True\n",
    "    ))\n",
    "name = 'A is more X than B. Who is more antonym(X)? B. Who is less X? B. Who is more X? A. Who is less antonym(X)? A.'\n",
    "test = MFT(**t, name=name, description='', capability='Taxonomy')\n",
    "test.run(new_pp)\n",
    "test.summary(n=3, format_example_fn=format_squad_with_context)\n",
    "suite.add(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robustness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "typos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_typo(x):\n",
    "    return (x[0], Perturb.add_typos(x[1]))\n",
    "t = Perturb.perturb(pairs, question_typo, nsamples=500)\n",
    "test = INV(**t, name='Question typo', capability='Robustness', description='')\n",
    "test.run(new_pp)\n",
    "test.summary(n=3, format_example_fn=format_squad)\n",
    "suite.add(test, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contractions(x):\n",
    "    conts = Perturb.contractions(x[1])\n",
    "    return [(x[0], a) for a in conts]\n",
    "t = Perturb.perturb(pairs, contractions, nsamples=500)\n",
    "test = INV(**t, name='Question contractions', capability='Robustness', description='')\n",
    "test.run(new_pp)\n",
    "test.summary(n=3, format_example_fn=format_squad)\n",
    "suite.add(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add random sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_sentences = set()\n",
    "for x, _ in processed_pairs:\n",
    "    for y in x.sents:\n",
    "        random_sentences.add(y.text)\n",
    "random_sentences = list(random_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(random_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_random_sentence(x, **kwargs):\n",
    "    random_s = np.random.choice(random_sentences)\n",
    "    while random_s in x[0]:\n",
    "        random_s = np.random.choice(random_sentences)\n",
    "    random_s = random_s.strip('.') + '. '\n",
    "    meta = ['add to end: %s' % random_s, 'add to beg: %s' % random_s]\n",
    "    return [(x[0] + random_s, x[1]), (random_s + x[0], x[1])], meta\n",
    "\n",
    "def format_add(x, pred, conf, label=None, meta=None):\n",
    "    ret = format_squad(x, pred, conf, label, meta)\n",
    "    if meta:\n",
    "        ret += 'Perturb: %s\\n' % meta\n",
    "    return ret\n",
    "\n",
    "t = Perturb.perturb(pairs, add_random_sentence, nsamples=500, meta=True)\n",
    "test = INV(**t, name='Add random sentence to context', capability='Robustness', description='')\n",
    "test.run(new_pp)\n",
    "test.summary(n=3, format_example_fn=format_add)\n",
    "suite.add(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def change_thing(change_fn):\n",
    "    def change_both(cq, **kwargs):\n",
    "        context, question = cq\n",
    "        a = change_fn(context, meta=True)\n",
    "        if not a:\n",
    "            return None\n",
    "        changed, meta = a\n",
    "        ret = []\n",
    "        for c, m in zip(changed, meta):\n",
    "            new_q = re.sub(r'\\b%s\\b' % re.escape(m[0]), m[1], question.text)\n",
    "            ret.append((c, new_q))\n",
    "        return ret, meta\n",
    "    return change_both\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expect_same(orig_pred, pred, orig_conf, conf, labels=None, meta=None):\n",
    "    if not meta:\n",
    "        return pred == orig_pred\n",
    "    return pred == re.sub(r'\\b%s\\b' % re.escape(meta[0]), meta[1], orig_pred)\n",
    "\n",
    "def format_replace(x, pred, conf, label=None, meta=None):\n",
    "    ret = format_squad(x, pred, conf, label, meta)\n",
    "    if meta:\n",
    "        ret += 'Perturb: %s -> %s\\n' % meta\n",
    "    return ret\n",
    "\n",
    "def format_replace_context(x, pred, conf, label=None, meta=None):\n",
    "    ret = format_squad_with_context(x, pred, conf, label, meta)\n",
    "    if meta:\n",
    "        ret += 'Perturb: %s -> %s\\n' % meta\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Perturb.perturb(processed_pairs, change_thing(Perturb.change_names), nsamples=500, meta=True)\n",
    "\n",
    "test = INV(**t, name='Change name everywhere', capability='NER',\n",
    "          description='', expect=Expect.pairwise(expect_same))\n",
    "test.run(new_pp)\n",
    "test.summary(3, format_example_fn=format_replace)\n",
    "suite.add(test, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Perturb.perturb(processed_pairs, change_thing(Perturb.change_location), nsamples=500, meta=True)\n",
    "\n",
    "test = INV(**t, name='Change location everywhere', capability='NER',\n",
    "          description='', expect=Expect.pairwise(expect_same))\n",
    "test.run(new_pp)\n",
    "test.summary(3, format_example_fn=format_replace)\n",
    "suite.add(test, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temporal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            'Both {first_name} and {first_name2} were {prof1}s, but there was a change in {first_name}, who is now {a:prof2}.',\n",
    "            'Both {first_name2} and {first_name} were {prof1}s, but there was a change in {first_name}, who is now {a:prof2}.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'Who is {a:prof2}?',\n",
    "                '{first_name}'\n",
    "            ), \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    save=True,\n",
    "    prof=professions,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=500,\n",
    "    ))\n",
    "name = 'There was a change in profession'\n",
    "test = MFT(**t, expect=expect_squad, capability='Temporal', name=name, description='' )\n",
    "test.run(new_pp)\n",
    "test.summary(n=3, format_example_fn=format_squad_with_context)\n",
    "suite.add(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{first_name} became a {prof} before {first_name2} did.',\n",
    "            '{first_name2} became a {prof} after {first_name} did.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'Who became a {prof} first?',\n",
    "                '{first_name}'\n",
    "            ), \n",
    "            (\n",
    "                'Who became a {prof} last?',\n",
    "                '{first_name2}'\n",
    "            ), \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    save=True,\n",
    "    prof=professions,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=500,\n",
    "    ))\n",
    "name = 'Understanding before / after -> first / last.'\n",
    "test = MFT(**t, expect=expect_squad, capability='Temporal', name=name, description='' )\n",
    "test.run(new_pp)\n",
    "test.summary(n=3, format_example_fn=format_squad_with_context)\n",
    "suite.add(test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Negation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{first_name} is not {a:prof}. {first_name2} is.',\n",
    "            '{first_name2} is {a:prof}. {first_name} is not.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'Who is {a:prof}?',\n",
    "                '{first_name2}'\n",
    "            ), \n",
    "            (\n",
    "                'Who is not {a:prof}?',\n",
    "                '{first_name}'\n",
    "            ), \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    save=True,\n",
    "    prof=professions,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=500,\n",
    "    ))\n",
    "name = 'Negation in context, may or may not be in question'\n",
    "test = MFT(**t, expect=expect_squad, capability='Negation', name=name, description='' )\n",
    "test.run(new_pp)\n",
    "test.summary(n=3, format_example_fn=format_squad_with_context)\n",
    "suite.add(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not in context:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "t = crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{first_name} is {a:prof}. {first_name2} is {a:prof2}.',\n",
    "            '{first_name2} is {a:prof2}. {first_name} is {a:prof}.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'Who is {a:prof}?',\n",
    "                '{first_name}'\n",
    "            ), \n",
    "            (\n",
    "                'Who is not {a:prof}?',\n",
    "                '{first_name2}'\n",
    "            ), \n",
    "            (\n",
    "                'Who is {a:prof2}?',\n",
    "                '{first_name2}'\n",
    "            ), \n",
    "            (\n",
    "                'Who is not {a:prof2}?',\n",
    "                '{first_name}'\n",
    "            ), \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    prof=professions,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=500,\n",
    "    ))\n",
    "name = 'Negation in question only.'\n",
    "test = MFT(**t, expect=expect_squad, capability='Negation', name=name, description='' )\n",
    "test.run(new_pp)\n",
    "test.summary(n=3, format_example_fn=format_squad_with_context)\n",
    "suite.add(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fairness spinoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "fewer_profs = ['doctor', 'nurse', 'secretary', 'CEO']\n",
    "t = editor.template(\n",
    "    [\n",
    "        ('{male} is not {a:prof}, {female} is.', 'Who is {a:prof}?', '{female}', 'woman', '{prof}'),\n",
    "        ('{female} is not {a:prof}, {male} is.', 'Who is {a:prof}?', '{male}', 'man', '{prof}'),\n",
    "    ],\n",
    "#     prof=professions + ['doctor'],\n",
    "    prof=fewer_profs,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=1000,\n",
    "    unroll=True,\n",
    "    save=True,\n",
    "    )\n",
    "data = [(d[0], d[1]) for d in t.data]\n",
    "labels = [d[2] for d in t.data]\n",
    "meta = [(d[3], d[4]) for d in t.data]\n",
    "\n",
    "test = MFT(data, expect=expect_squad, labels=labels, meta=meta, templates=t.templates,\n",
    "          name='M/F failure rates should be similar for different professions', capability='Fairness',\n",
    "          description='Using negation in context.')\n",
    "test.run(new_pp)\n",
    "\n",
    "def print_fair(test):\n",
    "    c = collections.Counter(test.meta)\n",
    "    fail = collections.Counter([tuple(x) for x in np.array(test.meta)[test.fail_idxs()]])\n",
    "    profs = set()\n",
    "    for sex, prof in fail:\n",
    "        profs.add(prof)\n",
    "    prof_fail = {}\n",
    "    get_fail = lambda f:fail[f] / c[f]\n",
    "    for prof in profs:\n",
    "        fail_m = get_fail(('man', prof))\n",
    "        fail_f = get_fail(('woman', prof))\n",
    "        prof_fail[prof] = (fail_m, fail_f)\n",
    "    print('%-13s fail_men fail_women (count)' % 'profession')\n",
    "    for prof, vs in sorted(prof_fail.items(), key=lambda x:max(x[1][0], x[1][1]), reverse=True):\n",
    "        fail_m, fail_f = vs\n",
    "        print('%-13s   %.1f      %.1f     (%d)' % (prof, 100 * fail_m, 100 * fail_f, c[('man', prof)]))\n",
    "print_fair(test)\n",
    "suite.add(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coref"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic coref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'actress' in professions:\n",
    "    professions.remove('actress')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{male} and {female} are friends. He is {a:prof1}, and she is {a:prof2}.',\n",
    "            '{female} and {male} are friends. He is {a:prof1}, and she is {a:prof2}.',\n",
    "            '{male} and {female} are friends. She is {a:prof2}, and he is {a:prof1}.',\n",
    "            '{female} and {male} are friends. She is {a:prof2}, and he is {a:prof1}.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'Who is {a:prof1}?',\n",
    "                '{male}'\n",
    "            ), \n",
    "            (\n",
    "                'Who is {a:prof2}?',\n",
    "                '{female}'\n",
    "            ), \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    save=True,\n",
    "    prof=professions,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=500,\n",
    "    ))\n",
    "name = 'Basic coref, he / she'\n",
    "test = MFT(**t, expect=expect_squad, name=name, description='', capability='Coref')\n",
    "test.run(new_pp)\n",
    "test.summary(n=3, format_example_fn=format_squad_with_context)\n",
    "suite.add(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{male} and {female} are friends. His mom is {a:prof}.',\n",
    "            '{female} and {male} are friends. His mom is {a:prof}.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'Whose mom is {a:prof}?',\n",
    "                '{male}'\n",
    "            ), \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    save=True,\n",
    "    prof=professions,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=250,\n",
    "    ))\n",
    "t += crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{male} and {female} are friends. Her mom is {a:prof}.',\n",
    "            '{female} and {male} are friends. Her mom is {a:prof}.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'Whose mom is {a:prof}?',\n",
    "                '{female}'\n",
    "            ), \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    save=True,\n",
    "    prof=professions,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=250,\n",
    "    ))\n",
    "\n",
    "name = 'Basic coref, his / her'\n",
    "test = MFT(**t, expect=expect_squad, name=name, description='', capability='Coref')\n",
    "test.run(new_pp)\n",
    "test.summary(n=3, format_example_fn=format_squad_with_context)\n",
    "suite.add(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Former, latter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{first_name} and {first_name2} are friends. The former is {a:prof1}.',\n",
    "            '{first_name2} and {first_name} are friends. The latter is {a:prof1}.',\n",
    "            '{first_name} and {first_name2} are friends. The former is {a:prof1} and the latter is {a:prof2}.',\n",
    "            '{first_name2} and {first_name} are friends. The former is {a:prof2} and the latter is {a:prof1}.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'Who is {a:prof1}?',\n",
    "                '{first_name}'\n",
    "            ), \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    prof=professions,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=500,\n",
    "    save=True\n",
    "    ))\n",
    "name = 'Former / Latter'\n",
    "test = MFT(**t, expect=expect_squad, name=name, description='', capability='Coref')\n",
    "test.run(new_pp)\n",
    "test.summary(n=3, format_example_fn=format_squad_with_context)\n",
    "suite.add(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SRL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pattern\n",
    "import pattern.en\n",
    "pverb = ['love', 'hate', 'like', 'remember', 'recognize', 'trust', 'deserve', 'understand', 'blame', 'dislike', 'prefer', 'follow', 'notice', 'hurt', 'bother', 'support', 'believe', 'accept', 'attack']\n",
    "a = pattern.en.tenses('loves')[0]\n",
    "b = pattern.en.tenses('stolen')[0]\n",
    "pverb = [(pattern.en.conjugate(v, *a), pattern.en.conjugate(v, *b)) for v in pverb]\n",
    "\n",
    "t = crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{first_name} {v[0]} {first_name2}.',\n",
    "            '{first_name2} is {v[1]} by {first_name}.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'Who {v[0]}?',\n",
    "                '{first_name}'\n",
    "            ), \n",
    "            (\n",
    "                'Who is {v[1]}?',\n",
    "                '{first_name2}'\n",
    "            ), \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    v=pverb,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=500,\n",
    "    ))\n",
    "name = 'Agent / object distinction'\n",
    "test = MFT(**t, expect=expect_squad, name=name, description='', capability='SRL')\n",
    "test.run(new_pp)\n",
    "test.summary(n=3, format_example_fn=format_squad_with_context)\n",
    "suite.add(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{first_name} {v[0]} {first_name2}. {first_name2} {v[0]} {first_name3}.',\n",
    "            '{first_name} {v[0]} {first_name2}. {first_name3} is {v[1]} by {first_name2}.',\n",
    "            '{first_name2} is {v[1]} by {first_name}. {first_name2} {v[0]} {first_name3}.',\n",
    "            '{first_name2} is {v[1]} by {first_name}. {first_name3} is {v[1]} by {first_name2}.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'Who {v[0]} {first_name2}?',\n",
    "                '{first_name}'\n",
    "            ), \n",
    "            (\n",
    "                'Who {v[0]} {first_name3}?',\n",
    "                '{first_name2}'\n",
    "            ), \n",
    "            (\n",
    "                'Who is {v[1]} by {first_name}?',\n",
    "                '{first_name2}'\n",
    "            ), \n",
    "            (\n",
    "                'Who is {v[1]} by {first_name2}?',\n",
    "                '{first_name3}'\n",
    "            ), \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    save=True,\n",
    "    v=pverb,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=500,\n",
    "    ))\n",
    "name = 'Agent / object distinction with 3 agents'\n",
    "test = MFT(**t, expect=expect_squad, name=name, description='', capability='SRL')\n",
    "test.run(new_pp)\n",
    "test.summary(n=3, format_example_fn=format_squad_with_context)\n",
    "suite.add(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/marcotcr/work/checklist/release_data/squad/squad_suite.pkl'\n",
    "suite.save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "suite.summary(n=3, format_example_fn=format_squad_with_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_fair(suite.tests['M/F failure rates should be similar for different professions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "format_fn = lambda x: json.dumps({'passage': x[0], 'question': x[1]})\n",
    "suite.to_raw_file('/tmp/squad.jsonl', format_fn=format_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "format_fn = lambda x: {'passage': x[0], 'question': x[1]}\n",
    "suite.to_raw_file('/tmp/squad.json', format_fn=format_fn, file_format='squad')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
